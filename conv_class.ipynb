{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np, pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing plugin EntryPoint(name='Windows (alt)', value='keyrings.alt.Windows', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/postyakov/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/importlib_metadata/__init__.py\", line 96, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/Windows.py\", line 9, in <module>\n",
      "    from . import file_base\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/file_base.py\", line 13, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Error initializing plugin EntryPoint(name='file', value='keyrings.alt.file', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/postyakov/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/importlib_metadata/__init__.py\", line 96, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/file.py\", line 11, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Error initializing plugin EntryPoint(name='pyfs', value='keyrings.alt.pyfs', group='keyring.backends').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/postyakov/.local/lib/python3.6/site-packages/keyring/backend.py\", line 203, in _load_plugins\n",
      "    init_func = ep.load()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/importlib_metadata/__init__.py\", line 96, in load\n",
      "    module = import_module(match.group('module'))\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/usr/lib/python3/dist-packages/keyrings/alt/pyfs.py\", line 8, in <module>\n",
      "    from keyring.util.escape import escape as escape_for_ini\n",
      "ModuleNotFoundError: No module named 'keyring.util.escape'\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.6/site-packages (4.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in ./.local/lib/python3.6/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from transformers) (1.6.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.0)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.6/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./.local/lib/python3.6/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./.local/lib/python3.6/site-packages (from requests->transformers) (1.25.7)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.6/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_cor.json') as data:\n",
    "    file = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = [] \n",
    "for d in file[:2]:\n",
    "    samples = defaultdict(dict)\n",
    "    result = d['completions'][0]['result']\n",
    "    texts_without_labels = d['data']['text']\n",
    "    for sample in result:\n",
    "        speaker = texts_without_labels[int(sample['value']['start'])]['speaker']\n",
    "        samples[sample['id']]['speaker'] = speaker\n",
    "        samples[sample['id']]['text'] = sample['value']['text']\n",
    "        samples[sample['id']]['start'] = int(sample['value']['start'])\n",
    "        if 'paragraphlabels' in sample['value']:\n",
    "            samples[sample['id']]['paragraphlabels'] = sample['value']['paragraphlabels'][0]\n",
    "        if 'choices' in sample['value']:\n",
    "            samples[sample['id']]['choices'] = sample['value']['choices'][0]\n",
    "    \n",
    "    sorted_samples = sorted([(samples[sample_id]['start'], sample_id) for sample_id in samples])\n",
    "    texts = []\n",
    "    labels = []\n",
    "    speakers = []\n",
    "    for _, sample_id in sorted_samples:\n",
    "        if samples[sample_id]['text'] != 'PAUSE':\n",
    "            texts.append(str(samples[sample_id]['text']).replace('\\n', ''))\n",
    "            speakers.append(samples[sample_id]['speaker'])\n",
    "            paragraph_labels = samples[sample_id].get('paragraphlabels', '')\n",
    "            choices = samples[sample_id].get('choices', '')\n",
    "#         if not choices:\n",
    "#             print(sample_id)\n",
    "            labels.append(paragraph_labels + '.' + choices)\n",
    "    dialogues.append((texts, labels, speakers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dialogues[1][0]\n",
    "test_data = dialogues[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = dialogues[1][1][1:]\n",
    "test_labels = dialogues[0][1][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "459"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speakers = dialogues[1][2]\n",
    "test_speakers = dialogues[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/bert-base-cased-conversational\")\n",
    "model = AutoModel.from_pretrained(\"DeepPavlov/bert-base-cased-conversational\")\n",
    "\n",
    "train_outputs = []\n",
    "for text in train_data:\n",
    "    with torch.no_grad():\n",
    "        input_ph= tokenizer(str(text).replace('?uh', ''), padding=True, truncation=True, max_length=30,return_tensors=\"pt\")\n",
    "        output_ph = model(**input_ph)\n",
    "#         train_outputs.append(output_ph.pooler_output.cpu().numpy()) \n",
    "        sentence_embedding = output_ph.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    train_outputs.append(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = []\n",
    "for text in test_data:\n",
    "    with torch.no_grad():\n",
    "        input_ph= tokenizer(str(text).replace('?uh', ''), padding=True, truncation=True, max_length=30,return_tensors=\"pt\")\n",
    "        output_ph = model(**input_ph)\n",
    "#        train_outputs.append(output_ph.pooler_output.cpu().numpy()) \n",
    "        sentence_embedding = output_ph.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    test_outputs.append(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = np.concatenate(test_outputs)\n",
    "test_concatenated = np.concatenate([test_outputs[1:],test_outputs[:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs = np.concatenate(train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_concatenated = np.concatenate([train_outputs[1:],train_outputs[:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 1536)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43688995,  0.19137517, -0.0198823 , ...,  0.8330983 ,\n",
       "         0.31290597, -0.03456344],\n",
       "       [ 0.05688643, -0.25340334, -0.44757494, ..., -0.25558057,\n",
       "         0.3885941 , -0.24909207],\n",
       "       [ 0.24975166,  0.29351747, -0.54521376, ...,  0.54846525,\n",
       "         0.07448874, -0.2684228 ],\n",
       "       ...,\n",
       "       [ 0.5119918 , -0.64941543,  0.1267632 , ..., -0.22897026,\n",
       "         0.54134154, -0.15236306],\n",
       "       [ 0.14594515, -0.0383253 ,  0.2194182 , ...,  0.42088524,\n",
       "         0.27806434,  0.33803844],\n",
       "       [ 0.4970232 , -0.10763296, -0.06794327, ..., -0.41754875,\n",
       "         0.48466605, -0.27968317]], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "model = LogisticRegression(C=0.1)\n",
    "model.fit(train_concatenated,train_labels)\n",
    "y_pred = model.predict(test_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
